# RE-VLM: Event-Augmented Vision-Language Model for Scene Understanding

**CVPR 2026**

> RE-VLM is the first dual-stream vision-language model that jointly leverages RGB images and event streams for robust scene understanding across both normal and challenging conditions.

```

### Deployment

This page is designed to be deployed via **GitHub Pages**. To enable:

## Citation

```bibtex

```

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.
